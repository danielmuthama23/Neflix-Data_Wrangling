{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54fd9bad-fad2-458e-ad8b-07de87879223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataset (R x C): (8807, 12)\n",
      "Columns in the dataset:\n",
      " ['show_id', 'type', 'title', 'director', 'cast', 'country', 'date_added', 'release_year', 'rating', 'duration', 'listed_in', 'description']\n",
      "Data types:\n",
      " show_id         object\n",
      "type            object\n",
      "title           object\n",
      "director        object\n",
      "cast            object\n",
      "country         object\n",
      "date_added      object\n",
      "release_year     int64\n",
      "rating          object\n",
      "duration        object\n",
      "listed_in       object\n",
      "description     object\n",
      "dtype: object\n",
      "Missing values per column:\n",
      " show_id            0\n",
      "type               0\n",
      "title              0\n",
      "director        2634\n",
      "cast             825\n",
      "country          831\n",
      "date_added        10\n",
      "release_year       0\n",
      "rating             4\n",
      "duration           3\n",
      "listed_in          0\n",
      "description        0\n",
      "dtype: int64\n",
      "Percentage of missing values:\n",
      " show_id          0.000000\n",
      "type             0.000000\n",
      "title            0.000000\n",
      "director        29.908028\n",
      "cast             9.367549\n",
      "country          9.435676\n",
      "date_added       0.113546\n",
      "release_year     0.000000\n",
      "rating           0.045418\n",
      "duration         0.034064\n",
      "listed_in        0.000000\n",
      "description      0.000000\n",
      "dtype: float64\n",
      "Number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "# Title: Neflix Data Wrangling\n",
    "# Name: Daniel Muthama\n",
    "# Date: 20 may 2025\n",
    "# Description: Extracts multi-page hockey team data into a structured CSV.\n",
    "\n",
    "# 1. Data Discovery\n",
    "# First, we load the dataset and explore its structure to understand the data types, missing values, and potential issues.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('netflix_titles.csv')\n",
    "\n",
    "# Data discovery\n",
    "print(\"Shape of the dataset (R x C):\", df.shape)\n",
    "print(\"Columns in the dataset:\\n\", df.columns.tolist())\n",
    "print(\"Data types:\\n\", df.dtypes)\n",
    "print(\"Missing values per column:\\n\", df.isnull().sum())\n",
    "print(\"Percentage of missing values:\\n\", (df.isnull().sum() / len(df)) * 100)\n",
    "print(\"Number of duplicate rows:\", df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eec504cc-4b3f-4725-b3ea-92cce4183b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Structuring the Data\n",
    "# Convert columns to appropriate data types and split composite fields.\n",
    "\n",
    "# Convert 'date_added' to datetime\n",
    "df['date_added'] = pd.to_datetime(df['date_added'], format='%B %d, %Y', errors='coerce')\n",
    "\n",
    "# Split 'duration' into numeric and unit\n",
    "df[['duration_value', 'duration_unit']] = df['duration'].str.extract(r'(\\d+)\\s*(\\w+)')\n",
    "df['duration_value'] = pd.to_numeric(df['duration_value'], errors='coerce')\n",
    "\n",
    "# Extract primary country (first country listed)\n",
    "df['primary_country'] = df['country'].str.split(',').str[0].str.strip()\n",
    "\n",
    "# Split genres into a list\n",
    "df['genres'] = df['listed_in'].str.split(', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4ac5989-a5c3-4f50-96ef-3de18a29c2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Cleaning the Data\n",
    "# Handle duplicates, missing values, and inconsistencies.\n",
    "\n",
    "# ------------- Fix: Convert lists to tuples or drop list-type columns -------------\n",
    "# If you have a 'genres' column created from splitting 'listed_in':\n",
    "df['genres'] = df['genres'].apply(lambda x: tuple(x) if isinstance(x, list) else x)\n",
    "\n",
    "# Alternatively, drop the 'genres' column if unused:\n",
    "# df.drop(columns=['genres'], inplace=True, errors='ignore')\n",
    "\n",
    "# Now safely drop duplicates\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "df.drop(columns=['description'], inplace=True)\n",
    "\n",
    "# -- Director Imputation --\n",
    "df['dir_cast'] = df['director'].fillna('Unknown') + '---' + df['cast'].fillna('Unknown')\n",
    "counts = df['dir_cast'].value_counts()\n",
    "filtered_counts = counts[counts >= 3]\n",
    "dict_direcast = {i.split('---', 1)[1]: i.split('---', 1)[0] for i in filtered_counts.index}\n",
    "\n",
    "for cast_val, director_val in dict_direcast.items():\n",
    "    df.loc[(df['director'].isna()) & (df['cast'] == cast_val), 'director'] = director_val\n",
    "\n",
    "df['director'].fillna('Not Given', inplace=True)\n",
    "\n",
    "# -- Country Imputation --\n",
    "director_country = df.dropna(subset=['country']).groupby('director')['country'].first().to_dict()\n",
    "df['country'] = df['director'].map(director_country).fillna(df['country'])\n",
    "df['country'].fillna('Not Given', inplace=True)\n",
    "\n",
    "# -- Final Cleaning --\n",
    "df['cast'].fillna('Not Given', inplace=True)\n",
    "df.dropna(subset=['date_added', 'rating', 'duration'], inplace=True)\n",
    "\n",
    "# Cleanup temporary columns\n",
    "df.drop(columns=['dir_cast'], inplace=True, errors='ignore')\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "504da3dc-ca1a-4595-874d-d85d84a0f585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Error Checking\n",
    "# Identify and correct logical inconsistencies.\n",
    "\n",
    "# Check for date_added before release_year\n",
    "invalid_dates = df[df['date_added'].dt.year < df['release_year']]\n",
    "df = df[df['date_added'].dt.year >= df['release_year']]\n",
    "\n",
    "# Ensure duration units are valid\n",
    "valid_units = ['min', 'Season', 'Seasons']\n",
    "df = df[df['duration_unit'].isin(valid_units)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4c4649a-ccd0-4e09-aa81-6359142cc0ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "show_id                    object\n",
      "type                       object\n",
      "title                      object\n",
      "director                   object\n",
      "cast                       object\n",
      "country                    object\n",
      "date_added         datetime64[ns]\n",
      "release_year                int64\n",
      "rating                     object\n",
      "duration                   object\n",
      "listed_in                  object\n",
      "duration_value            float64\n",
      "duration_unit              object\n",
      "primary_country            object\n",
      "genres                     object\n",
      "dtype: object\n",
      "show_id              0\n",
      "type                 0\n",
      "title                0\n",
      "director             0\n",
      "cast                 0\n",
      "country              0\n",
      "date_added           0\n",
      "release_year         0\n",
      "rating               0\n",
      "duration             0\n",
      "listed_in            0\n",
      "duration_value       0\n",
      "duration_unit        0\n",
      "primary_country    826\n",
      "genres               0\n",
      "dtype: int64\n",
      "Entries before 1997: 407\n"
     ]
    }
   ],
   "source": [
    "# 5. Validation\n",
    "# Ensure data integrity and correctness.\n",
    "\n",
    "# Check final data types\n",
    "print(df.dtypes)\n",
    "\n",
    "# Verify no missing values remain\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Check business rules (e.g., dates after 1997)\n",
    "print(\"Entries before 1997:\", df[df['release_year'] < 1997].shape[0])\n",
    "\n",
    "# Drop temporary columns and reset index\n",
    "df.drop(columns=['dir_cast'], inplace=True, errors='ignore')\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9d3b4f2-317a-4d71-8216-bdf01f6dff36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Export the Cleaned Data\n",
    "# Save the cleaned dataset for further analysis.\n",
    "\n",
    "\n",
    "df.to_csv('cleaned_netflix.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544f7b95-deab-4c2c-a7a3-70d07457e77b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
